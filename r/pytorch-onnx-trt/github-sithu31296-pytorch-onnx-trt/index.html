<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>ROS Index</title>
    <meta name="description" content="a community-maintained index of robotics software
">

    
    <link rel="canonical" href="http://index.rosdabbler.com/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt/">
    
    
    <link rel="icon" sizes="any" type="image/svg+xml" href="/assets/rosindex_logo.svg">

    

    <link rel="stylesheet" type="text/css" href="/bootstrap/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="/css/main.css">
    

    

    <script type="text/javascript" src=/js/jquery.js></script>
    <script src=/bootstrap/js/bootstrap.min.js type="text/javascript"></script>
    <script src=/js/jquery-cookie.js type="text/javascript"></script>
    
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EVD5Z6G6NH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EVD5Z6G6NH');
</script>

    <script type="text/javascript" src=/js/toc.js></script>

    <script src=/js/distro_switch.js></script>
  </head>

  <body>

    <header class="site-header">

  <div class="wrapper">
    <div class="container-fluid" style="margin-bottom: 10px">
      <div class="row">
        <!-- title -->
        <div class="col-xs-3" style="white-space:nowrap">
          <a class="site-title" href="/">
            <img src="/assets/rosindex_logo.svg" width="26" height="26" alt="ROS index logo" style="padding-bottom: 3px"/>
            ROS Index</a>
        </div>
        <!-- main internal links -->
        <div class="col-xs-6 text-center" style="padding:0px">
          <div class="btn-group hidden-xs" role="group" aria-label="..." style="padding: 6px">
            <div class="btn-group" role="group">
              <a href="/?search_packages=true" class="btn btn-default" role="button">Package List</a>
            </div>
            <div class="btn-group" role="group">
              <a href="/?search_repos=true" class="btn btn-default" role="button">Repository List</a>
            </div>
            <div class="btn-group" role="group">
              <a href="/search_deps" class="btn btn-default" role="button">System Dependencies</a>
            </div>
          </div>
          <div class="hidden-lg hidden-md hidden-sm">
            <button id="hLabel" class="btn btn-link dropdown-toggle" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              Lists <span class="caret"></span>
            </button>
            <ul class="dropdown-menu" aria-labelledby="hLabel">
              <li><a href="/?search_packages=true">Package List</a></li>
              <li><a href="/?search_repos=true">Repository List</a></li>
              <li><a href="/search_deps">System Dependencies</a></li>
            </ul>
          </div>
        </div>
        <!-- additional links -->
        <div class="col-xs-3 text-right" style="white-space:nowrap; padding:0px">
          <ul class="list-inline" style="margin-bottom:0px;">
            <li class="dropdown hidden-xs hidden-sm">
              <button id="rLabel" class="btn btn-link" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                ROS Resources <span class="caret"></span>
              </button>
              <ul class="dropdown-menu" role="menu" aria-labelledby="rLabel">
                <li><a href="http://docs.ros.org/">Documentation</a></li>
                <li><a href="http://wiki.ros.org/Support">Support</a></li>
                <li><a href="http://discourse.ros.org/">Discussion Forum</a></li>
                <li><a href="http://status.ros.org/">Service Status</a></li>
                <li><a href="https://robotics.stackexchange.com/questions/tagged/ros">ros @ Robotics Stack Exchange</a></li>
                <li><a href="https://docs.ros.org/en/ros2_packages/">Package API</a></li>
              </ul>
            </li>
            <li class="dropdown hidden-xs hidden-sm">
              <button id="aLabel" class="btn btn-link" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                About <span class="caret"></span>
              </button>
              <ul class="dropdown-menu dropdown-menu-right" role="menu" aria-labelledby="aLabel">
                <li><a href="/about">About </a></li>
                <li><a href="/contribute">Contribute</a></li>
                <li><a href="/help">Help</a></li>
                <li><a href="/stats">Stats</a></li>
              </ul>
            </li>
            <li class="dropdown hidden-md hidden-lg">
              <button id="qLabel" class="btn btn-link" type="button"
                      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                Resources <span class="caret"></span>
              </button>
              <ul class="dropdown-menu dropdown-menu-right" role="menu" aria-labelledby="qLabel">
                <li><a href="/about">About </a></li>
                <li><a href="/contribute">Contribute</a></li>
                <li><a href="/help">Help</a></li>
                <li><a href="/stats">Stats</a></li>
                <hr style="margin:7px" />
                <li><a href="http://docs.ros.org/">Documentation</a></li>
                <li><a href="http://wiki.ros.org/Support">Support</a></li>
                <li><a href="http://discourse.ros.org/">Discussion Forum</a></li>
                <li><a href="http://status.ros.org/">Service Status</a></li>
                <li><a href="https://robotics.stackexchange.com/questions/tagged/ros">ros @ Robotics Stack Exchange</a></li>
                <li><a href="https://docs.ros.org/en/ros2_packages/">Package API</a></li>
              </ul>
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="container-fluid" style="margin-top:20px">
  <div class="container-fluid">
    <div class="row">
      <ol class="breadcrumb">
        <li><a href="/">Home</a></li>
        <li><a href="/repos">Repos</a></li>
        <li class="active">pytorch-onnx-trt</li>
        <!--<li class="active">pytorch-onnx-trt</li>-->
      </ol>
    </div>
    <div class="row">
      

<div id="distro-switch" class="btn-group btn-group-justified" data-toggle="buttons">
  
    <label id="humble-option" class="distro-button btn btn-xs btn-default" href="#humble" data="humble">
      <input type="radio" name="options" id="humble-radio" autocomplete="off"> humble
    </label>
  
    <label id="jazzy-option" class="distro-button btn btn-xs btn-default" href="#jazzy" data="jazzy">
      <input type="radio" name="options" id="jazzy-radio" autocomplete="off"> jazzy
    </label>
  
    <label id="kilted-option" class="distro-button btn btn-xs btn-default" href="#kilted" data="kilted">
      <input type="radio" name="options" id="kilted-radio" autocomplete="off"> kilted
    </label>
  
    <label id="rolling-option" class="distro-button btn btn-xs btn-default" href="#rolling" data="rolling">
      <input type="radio" name="options" id="rolling-radio" autocomplete="off"> rolling
    </label>
  
    <label id="github-option" class="distro-button btn btn-xs btn-primary" href="#github" data="github">
      <input type="radio" name="options" id="github-radio" autocomplete="off"> github
    </label>
  
    <label id="noetic-option" class="distro-button btn btn-xs btn-default" href="#noetic" data="noetic">
      <input type="radio" name="options" id="noetic-radio" autocomplete="off"> noetic
    </label>
  

  <!-- Older distros -->
  <div class="btn-group dropdown">
    <label type="button" class="btn btn-xs dropdown-toggle btn-default" data-toggle="dropdown" id="older-distro-button">
        <input type="radio" name="options" autocomplete="off">
      <span id="older-label">Older</span>
      <span class="caret"></span>
    </label>
    <ul class="dropdown-menu" role="menu">
      
        <li data="galactic" id="galactic-option" class="disabled older-distro-option"  href="#galactic">
          <a href="#galactic" data="galactic" id="galactic-button">galactic</a>
        </li>
      
        <li data="iron" id="iron-option" class="disabled older-distro-option"  href="#iron">
          <a href="#iron" data="iron" id="iron-button">iron</a>
        </li>
      
        <li data="melodic" id="melodic-option" class="disabled older-distro-option"  href="#melodic">
          <a href="#melodic" data="melodic" id="melodic-button">melodic</a>
        </li>
      
    </ul>
  </div>
</div>

    </div>
    <div class="row">
      &nbsp;
    </div>
  </div>
</div>


  <div class="distro distro-humble">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/pytorch-onnx-trt">pytorch-onnx-trt</a> <small>repository</small></h3>
        
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-sithu31296-pytorch-onnx-trt
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-sithu31296-pytorch-onnx-trt" role="menuitem" tabindex="-1" href="/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt" data="github-sithu31296-pytorch-onnx-trt">
                    <span class="glyphicon glyphicon-star"></span>
                    github-sithu31296-pytorch-onnx-trt
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>humble</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-jazzy">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/pytorch-onnx-trt">pytorch-onnx-trt</a> <small>repository</small></h3>
        
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-sithu31296-pytorch-onnx-trt
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-sithu31296-pytorch-onnx-trt" role="menuitem" tabindex="-1" href="/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt" data="github-sithu31296-pytorch-onnx-trt">
                    <span class="glyphicon glyphicon-star"></span>
                    github-sithu31296-pytorch-onnx-trt
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>jazzy</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-kilted">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/pytorch-onnx-trt">pytorch-onnx-trt</a> <small>repository</small></h3>
        
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-sithu31296-pytorch-onnx-trt
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-sithu31296-pytorch-onnx-trt" role="menuitem" tabindex="-1" href="/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt" data="github-sithu31296-pytorch-onnx-trt">
                    <span class="glyphicon glyphicon-star"></span>
                    github-sithu31296-pytorch-onnx-trt
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>kilted</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-rolling">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/pytorch-onnx-trt">pytorch-onnx-trt</a> <small>repository</small></h3>
        
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-sithu31296-pytorch-onnx-trt
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-sithu31296-pytorch-onnx-trt" role="menuitem" tabindex="-1" href="/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt" data="github-sithu31296-pytorch-onnx-trt">
                    <span class="glyphicon glyphicon-star"></span>
                    github-sithu31296-pytorch-onnx-trt
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>rolling</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-github">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/pytorch-onnx-trt">pytorch-onnx-trt</a> <small>repository</small></h3>
        
        
        <a class="label label-primary pkg-label" href="/p/efficientdet">efficientdet</a>
        
        <a class="label label-primary pkg-label" href="/p/yolov4">yolov4</a>
        
        <a class="label label-primary pkg-label" href="/p/yolov5">yolov5</a>
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-sithu31296-pytorch-onnx-trt
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-sithu31296-pytorch-onnx-trt" role="menuitem" tabindex="-1" href="/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt" data="github-sithu31296-pytorch-onnx-trt">
                    <span class="glyphicon glyphicon-star"></span>
                    github-sithu31296-pytorch-onnx-trt
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        
        <div class="panel panel-default">
          
          <div class="panel-heading"><h3 class="panel-title">Repository Summary</h3></div>
          <div class="panel-body" style="overflow-x: auto">
            
  <link rel="stylesheet" href="/css/ci-status.css">
  <table class="table table-condensed">
    <tr>
      <td class="text-right"><b>Description</b></td>
      <td><span class="label label-default">TensortRT installation and Conversion from PyTorch Models</span></td>
    </tr>
    <tr>
      <td style="width:100px;" class="text-right"><b>Checkout URI</b></td>
      <td><a class="label label-default" href="https://github.com/sithu31296/pytorch-onnx-trt.git">https://github.com/sithu31296/pytorch-onnx-trt.git</a></td>
    </tr>
    <tr>
      <td class="text-right"><b>VCS Type</b></td>
      <td><span class="label label-default">git</span></td>
    </tr>
    <tr>
      <td class="text-right"><b>VCS Version</b></td>
      <td><span class="label label-default">master</span></td>
    </tr>
    <tr>
      <td style="white-space: nowrap;" class="text-right"><b>Last Updated</b></div>
      <td>
        
          <span class="label label-default"><span class="glyphicon glyphicon-time"></span> 2020-09-14
        </span>
      </td>
    </tr>
    <tr>
      <td class="text-right"><b>Dev Status</b></td>
      <td>
        
          <span class="label label-warning">UNKNOWN
        </span>
      </td>
    </tr>
              <tr>
                <td class="text-right"><b>CI status</b></td>
                <td class="ci-status">
                  
                  
                    <span class="label label-default" title="">No Continuous Integration</span>
                  
                </td>
              </tr>
    <tr>
      <td class="text-right"><b>Released</b></td>
      <td>
        
          <span class="label label-default">UNRELEASED
        </span>
      </td>
    </tr>
    <tr>
      <td class="text-right"><b>Tags</b></td>
      <td>
        
        
          <em>No category tags.</em>
        
      </td>
    </tr>
    <tr>
      <td class="text-right"><b>Contributing</b></td>
      <td>
        <a class="label label-primary" href="/r/pytorch-onnx-trt/#github-contribute-lists-help-wanted">
          Help Wanted (<span class="contribute-lists-help-wanted-count">0</span>)
        </a>
        <br>
        <a class="label label-primary" href="/r/pytorch-onnx-trt/#github-contribute-lists-good-first-issue">
          Good First Issues (<span class="contribute-lists-good-first-issue-count">0</span>)
        </a>
        <br>
        <a class="label label-primary" href="/r/pytorch-onnx-trt/#github-contribute-lists-pull-requests">
          Pull Requests to Review (<span class="contribute-lists-pull-requests-count">0</span>)
        </a>
      </td>
    </tr>
  </table>

          </div>
        </div>
        <div class="panel panel-default">
          <div class="panel-heading"><h3 class="panel-title">Packages</h3></div>
          <div class="panel-body">
            
            
              <table class="table table-condensed table-hover table-striped">
                <thead>
                  <tr>
                    <th>Name</th>
                    <th>Version</th>
                  </tr>
                </thead>
                <tbody>
                
                  <tr>
                    <td><a href="/p/efficientdet">efficientdet</a></td>
                    <td>0.0.0</td>
                  </tr>
                
                  <tr>
                    <td><a href="/p/yolov4">yolov4</a></td>
                    <td>0.0.0</td>
                  </tr>
                
                  <tr>
                    <td><a href="/p/yolov5">yolov5</a></td>
                    <td>0.0.0</td>
                  </tr>
                
                </tbody>
              </table>
            
          </div>
        </div>

        <div class="panel panel-default">
          <div class="panel-heading"><h3 class="panel-title">README</h3></div>
          <div class="panel-body">
            
              <div class="rendered-markdown">
<h1 id="tensorrt-conversion">TensorRT Conversion</h1>

<h3 style="color:#ac5353;"> PyTorch -&gt; ONNX -&gt; TensorRT </h3>

<p>This repo includes installation guide for TensorRT, how to convert PyTorch models to ONNX format and run inference with TensoRT Python API.</p>

<p>The following table compares the speed gain got from using TensorRT running <a href="https://github.com/ultralytics/yolov5">YOLOv5</a>.</p>

<table>
  <thead>
    <tr>
      <th>Device/ Env</th>
      <th>PyTorch (FP16)</th>
      <th>TensorRT (FP16)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>RTX 2060</td>
      <td>60-61</td>
      <td>96-97</td>
    </tr>
    <tr>
      <td>Jetson Xavier</td>
      <td>17-18</td>
      <td>38-39</td>
    </tr>
  </tbody>
</table>

<p><em>Notes: YOLO model in comparison is using YOLOv5-L with image size of 352x416. Units are in FPS.</em></p>

<p>Example conversion of YOLOv5 PyTorch Model to TensorRT is described in <code class="language-plaintext highlighter-rouge">examples</code> folder.</p>

<h2 id="installation">Installation</h2>

<p>Recommended CUDA version is</p>

<ul>
  <li>cuda-10.2 + cuDNN-7.6</li>
</ul>

<p>Tested environments:</p>

<ul>
  <li>CUDA 10.2 + cuDNN 7.6</li>
  <li>TensorRT 7.0.0.11</li>
  <li>ONNX 1.7</li>
  <li>ONNXRuntime 1.3</li>
  <li>Protobuf &gt;= 3.12.3</li>
  <li>CMake 3.15.2/ CMake 3.17.3</li>
  <li>PyTorch 1.5 + CUDA 10.2</li>
</ul>

<h3 id="protobuf">Protobuf</h3>

<p>Only Protobuf version &gt;= 3.12.3 is supported in ONNX_TENSORRT package. So, you need to build the latest version from source.</p>

<p>To build protobuf from source, the following tools are needed:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install </span>autoconf automake libtool curl make g++ unzip

</code></pre></div></div>

<p>Clone protobuf repository and make sure to also clone submodules and generated the configure script.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone <span class="nt">--recursive</span> https://github.com/protocolbuffers/protobuf.git
<span class="nb">cd </span>protobuf
./autogen.sh
./configure <span class="nt">--prefix</span><span class="o">=</span>/usr
make <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span>
<span class="nb">sudo </span>make <span class="nb">install 
sudo </span>ldconfig <span class="c"># refresh shared library cache</span>

</code></pre></div></div>

<p>Verify the installation:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>protoc <span class="nt">--version</span>

</code></pre></div></div>

<p>You should see the installed libprotoc version.</p>

<h3 id="nvidia-driver">NVIDIA Driver</h3>

<p>First detect your graphics card model and recommended driver.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ubuntu-drivers devices

</code></pre></div></div>

<p>If you don’t find your desired driver version, you can enable Nvidia beta driver repository.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>add-apt-repository ppa:graphics-drivers/ppa

</code></pre></div></div>

<p>Then install the desired driver version using:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install </span>nvidia-driver-440
<span class="nb">sudo </span>reboot

</code></pre></div></div>

<h3 id="cuda">CUDA</h3>

<p>Go to <a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA toolkit archive</a> and download your desired CUDA version and installation method.</p>

<p>Below is the sample installation method for CUDA 10.2 deb file.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin
<span class="nb">sudo mv </span>cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb
<span class="nb">sudo </span>dpkg <span class="nt">-i</span> cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb
<span class="nb">sudo </span>apt-key add /var/cuda-repo-10-2-local-10.2.89-440.33.01/7fa2af80.pub
<span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nt">-y</span> <span class="nb">install </span>cuda

</code></pre></div></div>

<p>Check using:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc <span class="nt">-V</span>

</code></pre></div></div>

<h3 id="cudnn">cuDNN</h3>

<p>Go to <a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> and download your desired cuDNN version.</p>

<p>You need to download <code class="language-plaintext highlighter-rouge">cuDNN Runtime Library</code> and <code class="language-plaintext highlighter-rouge">Developer Library</code>. <code class="language-plaintext highlighter-rouge">Code Samples and User Guide</code> is not essential.</p>

<p>Then install step by step:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>dpkg <span class="nt">-i</span> libcudnn8_x.x.x-1+cudax.x_amd64.deb
<span class="nb">sudo </span>dpkg <span class="nt">-i</span> libcudnn8-dev_8.x.x.x-1+cudax.x_amd64.deb

</code></pre></div></div>

<h3 id="tensorrt">TensorRT</h3>

<p>Download TensorRT from the following link:</p>

<p>https://developer.nvidia.com/tensorrt</p>

<p>Be careful to download to match with your CUDA install method. For example, if you installed CUDA with deb file, download TensorRT deb file also. Otherwise, it won’t work.</p>

<p>The following example will install TensorRT deb file method. For other version of TensoRT installation, please check <a href="https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-713/install-guide/index.html#installing">official documentation</a>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">os</span><span class="o">=</span><span class="s2">"ubuntu1x04"</span>
<span class="nv">tag</span><span class="o">=</span><span class="s2">"cudax.x-trt7.x.x.x-ga-yyyymmdd"</span>
<span class="nb">sudo </span>dpkg <span class="nt">-i</span> nv-tensorrt-repo-<span class="k">${</span><span class="nv">os</span><span class="k">}</span>-<span class="k">${</span><span class="nv">tag</span><span class="k">}</span>_1-1_amd64.deb

<span class="nb">sudo </span>apt-key add /var/nv-tensorrt-repo-<span class="k">${</span><span class="nv">tag</span><span class="k">}</span>/7fa2af80.pub

<span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nb">install </span>tensorrt cuda-nvrtc-x-y

</code></pre></div></div>

<p>Where x-y for cuda-nvrtc is 10-2 or 11-0 depending on your CUD version.</p>

<p>If you plan to use TensorRT with TensorFlow, install this:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install </span>uff-converter-tf

</code></pre></div></div>

<p>Verify the installation with</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dpkg <span class="nt">-l</span> | <span class="nb">grep </span>TensorRT

</code></pre></div></div>

<p>You should see libnvinfer, tensorrt and other related packages installed.</p>

<h3 id="pycuda">PyCUDA</h3>

<p>PyCUDA is used within Python wrappers to access NVIDIA’s CUDA APIs.</p>

<p>Install PyCUDA with the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>pycuda

</code></pre></div></div>

<p>If you faced this <code class="language-plaintext highlighter-rouge">error: command 'aarch64-linux-gnu-gcc' failed with exit status 1</code>, install like this: <code class="language-plaintext highlighter-rouge">pip3 install pycuda --user</code>.</p>

<p>If you cannot access cuda driver with PyCUDA, please uninstall PyCUDA, clean pip cache and install PyCUDA again.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 cache purge

</code></pre></div></div>

<p>To use the above command <code class="language-plaintext highlighter-rouge">pip3 cache purge</code>, you need to have pip version &gt;= 20.x.x.</p>

<h3 id="cmake">CMake</h3>

<p>CMake &gt;= 3.13 is required but on Ubuntu 18.04, installed version is 3.10.2. So, upgrade CMake.</p>

<p>Download latest CMake from <a href="https://github.com/Kitware/CMake/releases">here</a>.</p>

<p>Install OpenSSL:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install </span>libssl-dev

</code></pre></div></div>

<p>Then, install:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tar</span> <span class="nt">-xvzf</span> cmake-3.x.x.tar.gz
<span class="nb">cd </span>cmake-3.x.x
./bootstrap
make <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span>
<span class="nb">sudo </span>make <span class="nb">install</span>

</code></pre></div></div>

<p>Verify the installation:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cmake <span class="nt">--version</span>

</code></pre></div></div>

<h3 id="onnx_tensorrt">ONNX_TensorRT</h3>

<p>Parses ONNX models for execution with TensorRT.</p>

<p>Install Pre-requisities:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install </span>swig

</code></pre></div></div>

<p>Install ONNX_TRT:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/onnx/onnx-tensorrt
<span class="nb">cd </span>onnx-tensorrt
git submodule update <span class="nt">--init</span> <span class="nt">--recursive</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> build <span class="o">&amp;&amp;</span> <span class="nb">cd </span>build
cmake .. <span class="nt">-DTENSORRT_ROOT</span><span class="o">=</span>/usr/src/tensorrt
make <span class="nt">-j</span><span class="si">$(</span><span class="nb">nproc</span><span class="si">)</span>
<span class="nb">sudo </span>make <span class="nb">install
cd</span> ..
<span class="nb">sudo </span>python3 setup.py build
<span class="nb">sudo </span>python3 setup.py <span class="nb">install</span>

</code></pre></div></div>

<p>Possible errors when running <code class="language-plaintext highlighter-rouge">setup.py</code>:</p>
<ul>
  <li>
<code class="language-plaintext highlighter-rouge">error: command 'swig' failed with exit status 1</code>. To fix this, do the following: Add <code class="language-plaintext highlighter-rouge">#define TENSORRTAPI</code> at the top of <code class="language-plaintext highlighter-rouge">NvOnnxParser.h</code>.</li>
  <li>
<code class="language-plaintext highlighter-rouge">error: command 'aarch64-linux-gnu-gcc' failed with exit status 1</code>. This error will be occurred on Jetson platforms. To fix: Delete <code class="language-plaintext highlighter-rouge">'-m64,'</code> line in <code class="language-plaintext highlighter-rouge">setup.py</code> and try to re-build.</li>
</ul>

<h3 id="trtexec">trtexec</h3>

<p>A command line wrapper tool to serve two main purposes: benchmarking networks on random data and generating serialized engines from models.</p>

<p><code class="language-plaintext highlighter-rouge">trtexec</code> can build engines from models in Caffe, UFF (TensorFlow), or ONNX format.</p>

<p><code class="language-plaintext highlighter-rouge">trtexec</code> is included when you installed TensorRT but not enabled. You need to build to use it.</p>

<p>Switch to this <code class="language-plaintext highlighter-rouge">trtexec</code> directory and build it:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /usr/src/tensorrt/samples/trtexec/
<span class="nb">sudo </span>make

</code></pre></div></div>

<p>Then, the binary named <code class="language-plaintext highlighter-rouge">trtexec</code> will be created in <code class="language-plaintext highlighter-rouge">&lt;TensorRT root directory&gt;/bin</code>. Add this path in <code class="language-plaintext highlighter-rouge">.bashrc</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gedit ~/.bashrc

<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:/usr/src/tensorrt/bin

<span class="nb">source</span> ~/.bashrc

</code></pre></div></div>

<h3 id="onnx">ONNX</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>onnx

</code></pre></div></div>

<h3 id="onnxruntime">ONNXRuntime</h3>

<p>CPU:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>onnxruntime

</code></pre></div></div>

<p>GPU</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>onnxruntime-gpu

</code></pre></div></div>

<h3 id="onnx-simplifier">ONNX Simplifier</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>onnx-simplifier

</code></pre></div></div>

<h2 id="conversion">Conversion</h2>

<h3 id="pytorch-to-onnx">PyTorch to ONNX</h3>

<p>Run <code class="language-plaintext highlighter-rouge">onnx_export.py</code>.</p>

<p>Detail steps are as follows:</p>

<p>Load the PyTorch Model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">).</span><span class="nf">eval</span><span class="p">()</span>

</code></pre></div></div>

<p>Prepare the input:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

</code></pre></div></div>

<p>Note that height and width is fixed. Dynamic input shape is still not available in PyTorch » ONNX » TensorRT.</p>

<p>Export to ONNX format:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">onnx</span><span class="p">.</span><span class="nf">export</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>                  <span class="c1"># PyTorch Model
</span>    <span class="n">img</span><span class="p">,</span>                    <span class="c1"># Input tensor
</span>    <span class="n">f</span><span class="p">,</span>                      <span class="c1"># Output file (eg. 'output_model.onnx')
</span>    <span class="n">opset_version</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>       <span class="c1"># Operator support version
</span>    <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">image</span><span class="sh">'</span><span class="p">]</span>   <span class="c1"># Input tensor name (arbitary)
</span>    <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">output</span><span class="sh">'</span><span class="p">]</span> <span class="c1"># Output tensor name (arbitary)
</span><span class="p">)</span>

</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">opset_version</code> is very important. Some PyTorch operators are still not supported in ONNX even if <code class="language-plaintext highlighter-rouge">opset_version=12</code>. Default <code class="language-plaintext highlighter-rouge">opset_version</code> in PyTorch is 12. Please check official ONNX repo for supported PyTorch operators. If your model includes unsupported operators, convert to supported operators. For example, <code class="language-plaintext highlighter-rouge">torch.repeat_interleave()</code> is not supported, it can be converted into supported <code class="language-plaintext highlighter-rouge">torch.repeat() + torch.view()</code> to achieve the same function.</p>

<h3 id="onnx-simplifier-1">ONNX Simplifier</h3>

<p><code class="language-plaintext highlighter-rouge">onnxsim</code> will be used to simplify the exported ONNX model. This <code class="language-plaintext highlighter-rouge">onnxsim</code> will strip some unnecessary operations and will reduce the number of layers. Moreover, it will get rid of unsupported operators when converting to TensorRT.</p>

<p>An example before and after simplification from official repo is shown below:</p>

<p><img src="https://raw.githubusercontent.com/sithu31296/pytorch-onnx-trt/master/imgs/comparison.png" alt="comparison"></p>

<p>It includues optimizers from <code class="language-plaintext highlighter-rouge">onnx.optimizer</code>, eliminate constant nodes and can run with 3 versions:</p>

<h4 id="web-version">Web Version</h4>

<p>Open official published https://convertmodel.com page and choose ONNX as the output format and convert it.</p>

<h4 id="commandline-version">Commandline Version</h4>

<p>If the web version won’t work well, run the following command to simplify the ONNX model:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 <span class="nt">-m</span> onnxsim &lt;input_onnx_model&gt; &lt;output_onnx_model&gt;

</code></pre></div></div>

<p>For more available functions this command can do like skipping optimization and others:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 <span class="nt">-m</span> onnxsim <span class="nt">-h</span>

</code></pre></div></div>

<h4 id="python-in-script-version">Python In-Script Version</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">onnx</span>
<span class="kn">from</span> <span class="n">onnxsim</span> <span class="kn">import</span> <span class="n">simplify</span>

<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">simplified_model</span><span class="p">,</span> <span class="n">check</span> <span class="o">=</span> <span class="nf">simplify</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">check</span><span class="p">,</span> <span class="sh">"</span><span class="s">Simplified ONNX model could not be validated.</span><span class="sh">"</span>

<span class="n">onnx</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">simplified_model</span><span class="p">,</span> <span class="sh">'</span><span class="s">onnx_model_simplified.onnx</span><span class="sh">'</span><span class="p">)</span>

</code></pre></div></div>

<p>After all, check the exported ONNX model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">onnx</span><span class="p">.</span><span class="n">checker</span><span class="p">.</span><span class="nf">check_model</span><span class="p">(</span><span class="n">simplified_model</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">onnx</span><span class="p">.</span><span class="n">helper</span><span class="p">.</span><span class="nf">printable_graph</span><span class="p">(</span><span class="n">simplified_model</span><span class="p">.</span><span class="n">graph</span><span class="p">))</span>  <span class="c1"># print a human readable representation of the graph
</span>
</code></pre></div></div>

<p>You can view the ONNX model with this tool <a href="https://github.com/lutzroeder/netron">Netron</a>.</p>

<p><em>Note</em>: Don’t convert PyTorch to ONNX on Jetson; it will take more GPU memory usage. Try to do this on host PC. Sometimes, commandline method won’t work, so recommended method is In-script version.</p>

<h3 id="onnx-to-tensorrt-with-onnx-tensorrt">ONNX to TensorRT with onnx-tensorrt</h3>

<p><strong>ONNX-TensorRT</strong> package installed above will be used to convert the ONNX model (<code class="language-plaintext highlighter-rouge">.onnx</code>) to Tensort model (<code class="language-plaintext highlighter-rouge">.trt</code>).</p>

<p>You can also run <code class="language-plaintext highlighter-rouge">.onnx</code> model directly with TensorRT Python API but converting to <code class="language-plaintext highlighter-rouge">.trt</code> will be more convenient.</p>

<p>To convert, run the following command in your terminal:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>onnx2trt model.onnx <span class="nt">-o</span> model.trt <span class="nt">-b</span> 1 <span class="nt">-d</span> 16

</code></pre></div></div>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">-o</code>: To output TensorRT engine file</li>
  <li>
<code class="language-plaintext highlighter-rouge">-b</code>: Set batch size (default: 32)</li>
  <li>
<code class="language-plaintext highlighter-rouge">-d</code>: Set Model data type (16 for FP16, 32 for FP32)</li>
</ul>

<p>Please see other available options and their usage on official <a href="https://github.com/onnx/onnx-tensorrt">repo</a>.</p>

<p><em>Note</em>: Converted TRT model on one device will not result the same output on other device. This is more obvious if you use other optimization passes option. Try to run this on each device.</p>

<h3 id="onnx-to-tensorrt-with-trtexec">ONNX to TensorRT with trtexec</h3>

<p><code class="language-plaintext highlighter-rouge">trtexec</code> commandline tool can be used to convert the ONNX model instead of <code class="language-plaintext highlighter-rouge">onnx2trt</code>.</p>

<p>To convert ONNX model, run the following:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>trtexec <span class="nt">--onnx</span><span class="o">=</span>model.onnx <span class="nt">--saveEngine</span><span class="o">=</span>model.trt <span class="nt">--workspace</span><span class="o">=</span>1024 <span class="nt">--fp16</span>

</code></pre></div></div>

<p>It also includes model benchmarking and profiling. To see other available options and use cases, check out official <a href="https://github.com/NVIDIA/TensorRT/tree/master/samples/opensource/trtexec">Documentation</a>.</p>

<h2 id="run-trt-model">Run TRT Model</h2>

<p>First implement a logging interface through which TensorRT reports errors, warnings and informational messages.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorrt</span> <span class="k">as</span> <span class="n">trt</span>

<span class="n">TRT_LOGGER</span> <span class="o">=</span> <span class="n">trt</span><span class="p">.</span><span class="nc">Logger</span><span class="p">(</span><span class="n">trt</span><span class="p">.</span><span class="n">Logger</span><span class="p">.</span><span class="n">WARNING</span><span class="p">)</span>

</code></pre></div></div>

<p>Then, read the TRT model and deserialize it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">trt_model.trt</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">rb) as f, trt.Runtime(TRT_LOGGER) as runtime:
    engine = runtime.deserialize_cuda_engine(f.read())

</span></code></pre></div></div>

<p>Allocate some host and device buffers for inputs and outputs.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pycuda.driver</span> <span class="k">as</span> <span class="n">cuda</span>
<span class="kn">import</span> <span class="n">pycuda.autoinit</span>

<span class="n">h_input</span> <span class="o">=</span> <span class="n">cuda</span><span class="p">.</span><span class="nf">pagelocked_empty</span><span class="p">(</span><span class="n">trt</span><span class="p">.</span><span class="nf">volume</span><span class="p">(</span><span class="n">engine</span><span class="p">.</span><span class="nf">get_binding_shape</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">h_output</span> <span class="o">=</span> <span class="n">cuda</span><span class="p">.</span><span class="nf">pagelocked_empty</span><span class="p">(</span><span class="n">trt</span><span class="p">.</span><span class="nf">volume</span><span class="p">(</span><span class="n">engine</span><span class="p">.</span><span class="nf">get_binding_shape</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Allocate device memory for inputs and outputs.
</span><span class="n">d_input</span> <span class="o">=</span> <span class="n">cuda</span><span class="p">.</span><span class="nf">mem_alloc</span><span class="p">(</span><span class="n">h_input</span><span class="p">.</span><span class="n">nbytes</span><span class="p">)</span>
<span class="n">d_output</span> <span class="o">=</span> <span class="n">cuda</span><span class="p">.</span><span class="nf">mem_alloc</span><span class="p">(</span><span class="n">h_output</span><span class="p">.</span><span class="n">nbytes</span><span class="p">)</span>
<span class="c1"># Create a stream in which to copy inputs/outputs and run inference.
</span><span class="n">stream</span> <span class="o">=</span> <span class="n">cuda</span><span class="p">.</span><span class="nc">Stream</span><span class="p">()</span>

</code></pre></div></div>

<p>Finally, run inference with created engine:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">engine</span><span class="p">.</span><span class="nf">create_execution_context</span><span class="p">()</span> <span class="k">as</span> <span class="n">context</span><span class="p">:</span>
    <span class="c1"># Transfer input data to the GPU.
</span>    <span class="n">cuda</span><span class="p">.</span><span class="nf">memcpy_htod_async</span><span class="p">(</span><span class="n">d_input</span><span class="p">,</span> <span class="n">h_input</span><span class="p">,</span> <span class="n">stream</span><span class="p">)</span>
    <span class="c1"># Run inference.
</span>    <span class="n">context</span><span class="p">.</span><span class="nf">execute_async</span><span class="p">(</span><span class="n">bindings</span><span class="o">=</span><span class="p">[</span><span class="nf">int</span><span class="p">(</span><span class="n">d_input</span><span class="p">),</span> <span class="nf">int</span><span class="p">(</span><span class="n">d_output</span><span class="p">)],</span> <span class="n">stream_handle</span><span class="o">=</span><span class="n">stream</span><span class="p">.</span><span class="n">handle</span><span class="p">)</span>
    <span class="c1"># Transfer predictions back from the GPU.
</span>    <span class="n">cuda</span><span class="p">.</span><span class="nf">memcpy_dtoh_async</span><span class="p">(</span><span class="n">h_output</span><span class="p">,</span> <span class="n">d_output</span><span class="p">,</span> <span class="n">stream</span><span class="p">)</span>
    <span class="c1"># Synchronize the stream
</span>    <span class="n">stream</span><span class="p">.</span><span class="nf">synchronize</span><span class="p">()</span>
    <span class="c1"># Return the host output. 
</span>    <span class="k">return</span> <span class="n">h_output</span>

</code></pre></div></div>

<p>There is also an option to run ONNX model directly with TensorRT Python API, but it is not recommended.</p>

<h2 id="examples">Examples</h2>

<p>Example conversion of YOLOv5 model into TRT model can be seen in <a href="https://github.com/sithu31296/pytorch-onnx-trt/tree/master/conversion">conversion</a>.</p>

<p>You can see the example converted models in <a href="https://github.com/sithu31296/pytorch-onnx-trt/tree/master/examples">examples</a>.</p>

<h2 id="references">References</h2>

<ul>
  <li><a href="https://github.com/ultralytics/yolov5">YOLOv5</a></li>
  <li><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html">TensorRT Documentation</a></li>
  <li><a href="https://github.com/onnx/onnx">ONNX</a></li>
  <li><a href="https://github.com/microsoft/onnxruntime">ONNX-Runtime</a></li>
  <li><a href="https://github.com/onnx/onnx-tensorrt">ONNX-TensorRT</a></li>
  <li><a href="https://github.com/daquexian/onnx-simplifier">ONNX Simplifier</a></li>
  <li><a href="https://github.com/NVIDIA/TensorRT/tree/master/samples/opensource/trtexec">trtexec</a></li>
</ul>
</div>
            
          </div>
        </div>

        <div class="panel panel-default">
          <div class="panel-heading"><h3 class="panel-title">CONTRIBUTING</h3></div>
          <div class="panel-body">
            
              <em>No CONTRIBUTING.md found.</em>
            
          </div>
        </div>

        
        
      
    </div>
  </div>

  <div class="distro distro-noetic">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/pytorch-onnx-trt">pytorch-onnx-trt</a> <small>repository</small></h3>
        
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-sithu31296-pytorch-onnx-trt
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-sithu31296-pytorch-onnx-trt" role="menuitem" tabindex="-1" href="/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt" data="github-sithu31296-pytorch-onnx-trt">
                    <span class="glyphicon glyphicon-star"></span>
                    github-sithu31296-pytorch-onnx-trt
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>noetic</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-galactic">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/pytorch-onnx-trt">pytorch-onnx-trt</a> <small>repository</small></h3>
        
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-sithu31296-pytorch-onnx-trt
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-sithu31296-pytorch-onnx-trt" role="menuitem" tabindex="-1" href="/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt" data="github-sithu31296-pytorch-onnx-trt">
                    <span class="glyphicon glyphicon-star"></span>
                    github-sithu31296-pytorch-onnx-trt
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>galactic</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-iron">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/pytorch-onnx-trt">pytorch-onnx-trt</a> <small>repository</small></h3>
        
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-sithu31296-pytorch-onnx-trt
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-sithu31296-pytorch-onnx-trt" role="menuitem" tabindex="-1" href="/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt" data="github-sithu31296-pytorch-onnx-trt">
                    <span class="glyphicon glyphicon-star"></span>
                    github-sithu31296-pytorch-onnx-trt
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>iron</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-melodic">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/pytorch-onnx-trt">pytorch-onnx-trt</a> <small>repository</small></h3>
        
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-sithu31296-pytorch-onnx-trt
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-sithu31296-pytorch-onnx-trt" role="menuitem" tabindex="-1" href="/r/pytorch-onnx-trt/github-sithu31296-pytorch-onnx-trt" data="github-sithu31296-pytorch-onnx-trt">
                    <span class="glyphicon glyphicon-star"></span>
                    github-sithu31296-pytorch-onnx-trt
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>melodic</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>


<script src=/js/contribution_suggestions.js></script>
<script type="text/javascript">
  $(function() {
    setupContributeListTabLinks();
  });
  $(document).ready(function() {
    setupDistroSwitch("humble");
    setupContributeLists("https://github.com/sithu31296/pytorch-onnx-trt.git");
  });
</script>

      </div>
    </div>

    <footer class="site-footer">
  <div class="wrapper">
    <div class="container-fluid">
      <div style="float:left;">
        
          <a href="https://github.com/rkent/rosindex" title="Find rosindex in Github">
          <span class="icon  icon--github">
            <svg viewBox="0 0 16 16">
              <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
            </svg>
          </span>

          <span class="username">rkent/rosindex</span>
        </a>
        <em class="hidden-xs">| generated on 2025-05-05</em>
      
      </div>
      <div style="float:right;">
        <p class="text"><span class="hidden-xs">a community-maintained index of robotics software
 | </span><a href="/privacy.txt">privacy</a></p>
      </div>
    </div>
  </div>

</footer>


  </body>

</html>
