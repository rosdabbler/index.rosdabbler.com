<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>ROS Index</title>
    <meta name="description" content="a community-maintained index of robotics software
">

    
    <link rel="canonical" href="http://index.rosdabbler.com/r/llama_ros/github-mgonzs13-llama_ros/">
    
    
    <link rel="icon" sizes="any" type="image/svg+xml" href="/assets/rosindex_logo.svg">

    

    <link rel="stylesheet" type="text/css" href="/bootstrap/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="/css/main.css">
    

    

    <script type="text/javascript" src=/js/jquery.js></script>
    <script src=/bootstrap/js/bootstrap.min.js type="text/javascript"></script>
    <script src=/js/jquery-cookie.js type="text/javascript"></script>
    
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EVD5Z6G6NH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EVD5Z6G6NH');
</script>

    <script type="text/javascript" src=/js/toc.js></script>

    <script src=/js/distro_switch.js></script>
  </head>

  <body>

    <header class="site-header">

  <div class="wrapper">
    <div class="container-fluid" style="margin-bottom: 10px">
      <div class="row">
        <!-- title -->
        <div class="col-xs-3" style="white-space:nowrap">
          <a class="site-title" href="/">
            <img src="/assets/rosindex_logo.svg" width="26" height="26" alt="ROS index logo" style="padding-bottom: 3px"/>
            ROS Index</a>
        </div>
        <!-- main internal links -->
        <div class="col-xs-6 text-center" style="padding:0px">
          <div class="btn-group hidden-xs" role="group" aria-label="..." style="padding: 6px">
            <div class="btn-group" role="group">
              <a href="/?search_packages=true" class="btn btn-default" role="button">Package List</a>
            </div>
            <div class="btn-group" role="group">
              <a href="/?search_repos=true" class="btn btn-default" role="button">Repository List</a>
            </div>
            <div class="btn-group" role="group">
              <a href="/search_deps" class="btn btn-default" role="button">System Dependencies</a>
            </div>
          </div>
          <div class="hidden-lg hidden-md hidden-sm">
            <button id="hLabel" class="btn btn-link dropdown-toggle" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              Lists <span class="caret"></span>
            </button>
            <ul class="dropdown-menu" aria-labelledby="hLabel">
              <li><a href="/?search_packages=true">Package List</a></li>
              <li><a href="/?search_repos=true">Repository List</a></li>
              <li><a href="/search_deps">System Dependencies</a></li>
            </ul>
          </div>
        </div>
        <!-- additional links -->
        <div class="col-xs-3 text-right" style="white-space:nowrap; padding:0px">
          <ul class="list-inline" style="margin-bottom:0px;">
            <li class="dropdown hidden-xs hidden-sm">
              <button id="rLabel" class="btn btn-link" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                ROS Resources <span class="caret"></span>
              </button>
              <ul class="dropdown-menu" role="menu" aria-labelledby="rLabel">
                <li><a href="http://docs.ros.org/">Documentation</a></li>
                <li><a href="http://wiki.ros.org/Support">Support</a></li>
                <li><a href="http://discourse.ros.org/">Discussion Forum</a></li>
                <li><a href="http://status.ros.org/">Service Status</a></li>
                <li><a href="https://robotics.stackexchange.com/questions/tagged/ros">ros @ Robotics Stack Exchange</a></li>
                <li><a href="https://docs.ros.org/en/ros2_packages/">Package API</a></li>
              </ul>
            </li>
            <li class="dropdown hidden-xs hidden-sm">
              <button id="aLabel" class="btn btn-link" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                About <span class="caret"></span>
              </button>
              <ul class="dropdown-menu dropdown-menu-right" role="menu" aria-labelledby="aLabel">
                <li><a href="/about">About </a></li>
                <li><a href="/contribute">Contribute</a></li>
                <li><a href="/help">Help</a></li>
                <li><a href="/stats">Stats</a></li>
              </ul>
            </li>
            <li class="dropdown hidden-md hidden-lg">
              <button id="qLabel" class="btn btn-link" type="button"
                      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                Resources <span class="caret"></span>
              </button>
              <ul class="dropdown-menu dropdown-menu-right" role="menu" aria-labelledby="qLabel">
                <li><a href="/about">About </a></li>
                <li><a href="/contribute">Contribute</a></li>
                <li><a href="/help">Help</a></li>
                <li><a href="/stats">Stats</a></li>
                <hr style="margin:7px" />
                <li><a href="http://docs.ros.org/">Documentation</a></li>
                <li><a href="http://wiki.ros.org/Support">Support</a></li>
                <li><a href="http://discourse.ros.org/">Discussion Forum</a></li>
                <li><a href="http://status.ros.org/">Service Status</a></li>
                <li><a href="https://robotics.stackexchange.com/questions/tagged/ros">ros @ Robotics Stack Exchange</a></li>
                <li><a href="https://docs.ros.org/en/ros2_packages/">Package API</a></li>
              </ul>
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="container-fluid" style="margin-top:20px">
  <div class="container-fluid">
    <div class="row">
      <ol class="breadcrumb">
        <li><a href="/">Home</a></li>
        <li><a href="/repos">Repos</a></li>
        <li class="active">llama_ros</li>
        <!--<li class="active">llama_ros</li>-->
      </ol>
    </div>
    <div class="row">
      

<div id="distro-switch" class="btn-group btn-group-justified" data-toggle="buttons">
  
    <label id="humble-option" class="distro-button btn btn-xs btn-default" href="#humble" data="humble">
      <input type="radio" name="options" id="humble-radio" autocomplete="off"> humble
    </label>
  
    <label id="jazzy-option" class="distro-button btn btn-xs btn-default" href="#jazzy" data="jazzy">
      <input type="radio" name="options" id="jazzy-radio" autocomplete="off"> jazzy
    </label>
  
    <label id="kilted-option" class="distro-button btn btn-xs btn-default" href="#kilted" data="kilted">
      <input type="radio" name="options" id="kilted-radio" autocomplete="off"> kilted
    </label>
  
    <label id="rolling-option" class="distro-button btn btn-xs btn-default" href="#rolling" data="rolling">
      <input type="radio" name="options" id="rolling-radio" autocomplete="off"> rolling
    </label>
  
    <label id="github-option" class="distro-button btn btn-xs btn-primary" href="#github" data="github">
      <input type="radio" name="options" id="github-radio" autocomplete="off"> github
    </label>
  
    <label id="noetic-option" class="distro-button btn btn-xs btn-default" href="#noetic" data="noetic">
      <input type="radio" name="options" id="noetic-radio" autocomplete="off"> noetic
    </label>
  

  <!-- Older distros -->
  <div class="btn-group dropdown">
    <label type="button" class="btn btn-xs dropdown-toggle btn-default" data-toggle="dropdown" id="older-distro-button">
        <input type="radio" name="options" autocomplete="off">
      <span id="older-label">Older</span>
      <span class="caret"></span>
    </label>
    <ul class="dropdown-menu" role="menu">
      
        <li data="galactic" id="galactic-option" class="disabled older-distro-option"  href="#galactic">
          <a href="#galactic" data="galactic" id="galactic-button">galactic</a>
        </li>
      
        <li data="iron" id="iron-option" class="disabled older-distro-option"  href="#iron">
          <a href="#iron" data="iron" id="iron-button">iron</a>
        </li>
      
        <li data="melodic" id="melodic-option" class="disabled older-distro-option"  href="#melodic">
          <a href="#melodic" data="melodic" id="melodic-button">melodic</a>
        </li>
      
    </ul>
  </div>
</div>

    </div>
    <div class="row">
      &nbsp;
    </div>
  </div>
</div>


  <div class="distro distro-humble">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/llama_ros">llama_ros</a> <small>repository</small></h3>
        <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-mgonzs13-llama_ros
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-mgonzs13-llama_ros" role="menuitem" tabindex="-1" href="/r/llama_ros/github-mgonzs13-llama_ros" data="github-mgonzs13-llama_ros">
                    <span class="glyphicon glyphicon-star"></span>
                    github-mgonzs13-llama_ros
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>humble</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-jazzy">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/llama_ros">llama_ros</a> <small>repository</small></h3>
        <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-mgonzs13-llama_ros
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-mgonzs13-llama_ros" role="menuitem" tabindex="-1" href="/r/llama_ros/github-mgonzs13-llama_ros" data="github-mgonzs13-llama_ros">
                    <span class="glyphicon glyphicon-star"></span>
                    github-mgonzs13-llama_ros
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>jazzy</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-kilted">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/llama_ros">llama_ros</a> <small>repository</small></h3>
        <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-mgonzs13-llama_ros
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-mgonzs13-llama_ros" role="menuitem" tabindex="-1" href="/r/llama_ros/github-mgonzs13-llama_ros" data="github-mgonzs13-llama_ros">
                    <span class="glyphicon glyphicon-star"></span>
                    github-mgonzs13-llama_ros
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>kilted</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-rolling">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/llama_ros">llama_ros</a> <small>repository</small></h3>
        <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-mgonzs13-llama_ros
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-mgonzs13-llama_ros" role="menuitem" tabindex="-1" href="/r/llama_ros/github-mgonzs13-llama_ros" data="github-mgonzs13-llama_ros">
                    <span class="glyphicon glyphicon-star"></span>
                    github-mgonzs13-llama_ros
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>rolling</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-github">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/llama_ros">llama_ros</a> <small>repository</small></h3>
        <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        
        <a class="label label-primary pkg-label" href="/p/llama_bringup">llama_bringup</a>
        
        <a class="label label-primary pkg-label" href="/p/llama_bt">llama_bt</a>
        
        <a class="label label-primary pkg-label" href="/p/llama_cli">llama_cli</a>
        
        <a class="label label-primary pkg-label" href="/p/llama_cpp_vendor">llama_cpp_vendor</a>
        
        <a class="label label-primary pkg-label" href="/p/llama_demos">llama_demos</a>
        
        <a class="label label-primary pkg-label" href="/p/llama_hfhub_vendor">llama_hfhub_vendor</a>
        
        <a class="label label-primary pkg-label" href="/p/llama_msgs">llama_msgs</a>
        
        <a class="label label-primary pkg-label" href="/p/llama_ros">llama_ros</a>
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-mgonzs13-llama_ros
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-mgonzs13-llama_ros" role="menuitem" tabindex="-1" href="/r/llama_ros/github-mgonzs13-llama_ros" data="github-mgonzs13-llama_ros">
                    <span class="glyphicon glyphicon-star"></span>
                    github-mgonzs13-llama_ros
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        
        <div class="panel panel-default">
          
          <div class="panel-heading"><h3 class="panel-title">Repository Summary</h3></div>
          <div class="panel-body" style="overflow-x: auto">
            
  <link rel="stylesheet" href="/css/ci-status.css">
  <table class="table table-condensed">
    <tr>
      <td class="text-right"><b>Description</b></td>
      <td><span class="label label-default">llama.cpp (GGUF LLMs) and llava.cpp (GGUF VLMs) for ROS 2</span></td>
    </tr>
    <tr>
      <td style="width:100px;" class="text-right"><b>Checkout URI</b></td>
      <td><a class="label label-default" href="https://github.com/mgonzs13/llama_ros.git">https://github.com/mgonzs13/llama_ros.git</a></td>
    </tr>
    <tr>
      <td class="text-right"><b>VCS Type</b></td>
      <td><span class="label label-default">git</span></td>
    </tr>
    <tr>
      <td class="text-right"><b>VCS Version</b></td>
      <td><span class="label label-default">main</span></td>
    </tr>
    <tr>
      <td style="white-space: nowrap;" class="text-right"><b>Last Updated</b></div>
      <td>
        
          <span class="label label-default"><span class="glyphicon glyphicon-time"></span> 2025-04-29
        </span>
      </td>
    </tr>
    <tr>
      <td class="text-right"><b>Dev Status</b></td>
      <td>
        
          <span class="label label-warning">UNKNOWN
        </span>
      </td>
    </tr>
              <tr>
                <td class="text-right"><b>CI status</b></td>
                <td class="ci-status">
                  
                  
                    <span class="label label-default" title="">No Continuous Integration</span>
                  
                </td>
              </tr>
    <tr>
      <td class="text-right"><b>Released</b></td>
      <td>
        
          <span class="label label-default">UNRELEASED
        </span>
      </td>
    </tr>
    <tr>
      <td class="text-right"><b>Tags</b></td>
      <td>
        
        
          <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        
      </td>
    </tr>
    <tr>
      <td class="text-right"><b>Contributing</b></td>
      <td>
        <a class="label label-primary" href="/r/llama_ros/#github-contribute-lists-help-wanted">
          Help Wanted (<span class="contribute-lists-help-wanted-count">0</span>)
        </a>
        <br>
        <a class="label label-primary" href="/r/llama_ros/#github-contribute-lists-good-first-issue">
          Good First Issues (<span class="contribute-lists-good-first-issue-count">0</span>)
        </a>
        <br>
        <a class="label label-primary" href="/r/llama_ros/#github-contribute-lists-pull-requests">
          Pull Requests to Review (<span class="contribute-lists-pull-requests-count">0</span>)
        </a>
      </td>
    </tr>
  </table>

          </div>
        </div>
        <div class="panel panel-default">
          <div class="panel-heading"><h3 class="panel-title">Packages</h3></div>
          <div class="panel-body">
            
            
              <table class="table table-condensed table-hover table-striped">
                <thead>
                  <tr>
                    <th>Name</th>
                    <th>Version</th>
                  </tr>
                </thead>
                <tbody>
                
                  <tr>
                    <td><a href="/p/llama_bringup">llama_bringup</a></td>
                    <td>5.0.1</td>
                  </tr>
                
                  <tr>
                    <td><a href="/p/llama_bt">llama_bt</a></td>
                    <td>1.0.0</td>
                  </tr>
                
                  <tr>
                    <td><a href="/p/llama_cli">llama_cli</a></td>
                    <td>5.0.1</td>
                  </tr>
                
                  <tr>
                    <td><a href="/p/llama_cpp_vendor">llama_cpp_vendor</a></td>
                    <td>5.0.1</td>
                  </tr>
                
                  <tr>
                    <td><a href="/p/llama_demos">llama_demos</a></td>
                    <td>5.0.1</td>
                  </tr>
                
                  <tr>
                    <td><a href="/p/llama_hfhub_vendor">llama_hfhub_vendor</a></td>
                    <td>5.0.1</td>
                  </tr>
                
                  <tr>
                    <td><a href="/p/llama_msgs">llama_msgs</a></td>
                    <td>5.0.1</td>
                  </tr>
                
                  <tr>
                    <td><a href="/p/llama_ros">llama_ros</a></td>
                    <td>5.0.1</td>
                  </tr>
                
                </tbody>
              </table>
            
          </div>
        </div>

        <div class="panel panel-default">
          <div class="panel-heading"><h3 class="panel-title">README</h3></div>
          <div class="panel-body">
            
              <div class="rendered-markdown">
<h1 id="llama_ros">llama_ros</h1>

<p>This repository provides a set of ROS 2 packages to integrate <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> into ROS 2. Using the llama_ros packages, you can easily incorporate the powerful optimization capabilities of <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> into your ROS 2 projects by running <a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md">GGUF</a>-based <a href="https://huggingface.co/models?sort=trending&amp;search=gguf+7b">LLMs</a> and <a href="https://huggingface.co/models?sort=trending&amp;search=gguf+llava">VLMs</a>. You can also use features from llama.cpp such as <a href="https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md">GBNF grammars</a> and modify LoRAs in real-time.</p>

<div align="center">

[![License: MIT](https://img.shields.io/badge/GitHub-MIT-informational)](https://opensource.org/license/mit) [![GitHub release](https://img.shields.io/github/release/mgonzs13/llama_ros.svg)](https://github.com/mgonzs13/llama_ros/releases) [![Code Size](https://img.shields.io/github/languages/code-size/mgonzs13/llama_ros.svg?branch=main)](https://github.com/mgonzs13/llama_ros?branch=main) [![Last Commit](https://img.shields.io/github/last-commit/mgonzs13/llama_ros.svg)](https://github.com/mgonzs13/llama_ros/commits/main) [![GitHub issues](https://img.shields.io/github/issues/mgonzs13/llama_ros)](https://github.com/mgonzs13/llama_ros/issues) [![GitHub pull requests](https://img.shields.io/github/issues-pr/mgonzs13/llama_ros)](https://github.com/mgonzs13/llama_ros/pulls) [![Contributors](https://img.shields.io/github/contributors/mgonzs13/llama_ros.svg)](https://github.com/mgonzs13/llama_ros/graphs/contributors) [![Python Formatter Check](https://github.com/mgonzs13/llama_ros/actions/workflows/python-formatter.yml/badge.svg?branch=main)](https://github.com/mgonzs13/llama_ros/actions/workflows/python-formatter.yml?branch=main) [![C++ Formatter Check](https://github.com/mgonzs13/llama_ros/actions/workflows/cpp-formatter.yml/badge.svg?branch=main)](https://github.com/mgonzs13/llama_ros/actions/workflows/cpp-formatter.yml?branch=main)

| ROS 2 Distro |                          Branch                           |                                                                                                     Build status                                                                                                      |                                                               Docker Image                                                               | Documentation                                                                                                                                                  |
| :----------: | :-------------------------------------------------------: | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------: | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|  **Humble**  | [`main`](https://github.com/mgonzs13/llama_ros/tree/main) | [![Humble Build](https://github.com/mgonzs13/llama_ros/actions/workflows/humble-docker-build.yml/badge.svg?branch=main)](https://github.com/mgonzs13/llama_ros/actions/workflows/humble-docker-build.yml?branch=main) | [![Docker Image](https://img.shields.io/badge/Docker%20Image%20-humble-blue)](https://hub.docker.com/r/mgons/llama_ros/tags?name=humble) | [![Doxygen Deployment](https://github.com/mgonzs13/llama_ros/actions/workflows/doxygen-deployment.yml/badge.svg)](https://mgonzs13.github.io/llama_ros/latest) |
|  **Jazzy**   | [`main`](https://github.com/mgonzs13/llama_ros/tree/main) |  [![Jazzy Build](https://github.com/mgonzs13/llama_ros/actions/workflows/jazzy-docker-build.yml/badge.svg?branch=main)](https://github.com/mgonzs13/llama_ros/actions/workflows/jazzy-docker-build.yml?branch=main)   |  [![Docker Image](https://img.shields.io/badge/Docker%20Image%20-jazzy-blue)](https://hub.docker.com/r/mgons/llama_ros/tags?name=jazzy)  | [![Doxygen Deployment](https://github.com/mgonzs13/llama_ros/actions/workflows/doxygen-deployment.yml/badge.svg)](https://mgonzs13.github.io/llama_ros/latest) |

</div>

<h2 id="table-of-contents">Table of Contents</h2>

<ol>
  <li><a href="https://github.com/mgonzs13/llama_ros/tree/main/#related-projects">Related Projects</a></li>
  <li><a href="https://github.com/mgonzs13/llama_ros/tree/main/#installation">Installation</a></li>
  <li><a href="https://github.com/mgonzs13/llama_ros/tree/main/#docker">Docker</a></li>
  <li>
<a href="https://github.com/mgonzs13/llama_ros/tree/main/#usage">Usage</a>
    <ul>
      <li><a href="https://github.com/mgonzs13/llama_ros/tree/main/#llama_cli">llama_cli</a></li>
      <li><a href="https://github.com/mgonzs13/llama_ros/tree/main/#launch-files">Launch Files</a></li>
      <li><a href="https://github.com/mgonzs13/llama_ros/tree/main/#lora-adapters">LoRA Adapters</a></li>
      <li><a href="https://github.com/mgonzs13/llama_ros/tree/main/#ros-2-clients">ROS 2 Clients</a></li>
      <li><a href="https://github.com/mgonzs13/llama_ros/tree/main/#langchain">LangChain</a></li>
    </ul>
  </li>
  <li><a href="https://github.com/mgonzs13/llama_ros/tree/main/#demos">Demos</a></li>
</ol>

<h2 id="related-projects">Related Projects</h2>

<ul>
  <li>
<a href="https://github.com/mgonzs13/chatbot_ros">chatbot_ros</a> → This chatbot, integrated into ROS 2, uses <a href="https://github.com/mgonzs13/whisper_ros/tree/main">whisper_ros</a>, to listen to people speech; and llama_ros, to generate responses. The chatbot is controlled by a state machine created with <a href="https://github.com/uleroboticsgroup/yasmin">YASMIN</a>.</li>
  <li>
<a href="https://github.com/Dsobh/explainable_ROS">explainable_ros</a> → A ROS 2 tool to explain the behavior of a robot. Using the integration of LangChain, logs are stored in a vector database. Then, RAG is applied to retrieve relevant logs for user questions answered with llama_ros.</li>
</ul>

<h2 id="installation">Installation</h2>

<p>To run llama_ros with CUDA, first, you must install the <a href="https://developer.nvidia.com/cuda-toolkit">CUDA Toolkit</a>. Then, you can compile llama_ros with <code class="language-plaintext highlighter-rouge">--cmake-args -DGGML_CUDA=ON</code> to enable CUDA support.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros2_ws/src
git clone https://github.com/mgonzs13/llama_ros.git
pip3 <span class="nb">install</span> <span class="nt">-r</span> llama_ros/requirements.txt
<span class="nb">cd</span> ~/ros2_ws
rosdep <span class="nb">install</span> <span class="nt">--from-paths</span> src <span class="nt">--ignore-src</span> <span class="nt">-r</span> <span class="nt">-y</span>
colcon build <span class="nt">--cmake-args</span> <span class="nt">-DGGML_CUDA</span><span class="o">=</span>ON <span class="c"># add this for CUDA</span>

</code></pre></div></div>

<h2 id="docker">Docker</h2>

<p>Build the llama_ros docker or download an image from <a href="https://hub.docker.com/repository/docker/mgons/llama_ros">DockerHub</a>. You can choose to build llama_ros with CUDA (<code class="language-plaintext highlighter-rouge">USE_CUDA</code>) and choose the CUDA version (<code class="language-plaintext highlighter-rouge">CUDA_VERSION</code>). Remember that you have to use <code class="language-plaintext highlighter-rouge">DOCKER_BUILDKIT=0</code> to compile llama_ros with CUDA when building the image.</p>

<!-- To build using CUDA you have to install the [NVIDIA Container Tollkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) and [configure the default runtime to NVIDIA](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/1.12.1/user-guide.html#daemon-configuration-file). -->

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">DOCKER_BUILDKIT</span><span class="o">=</span>0 docker build <span class="nt">-t</span> llama_ros <span class="nt">--build-arg</span> <span class="nv">USE_CUDA</span><span class="o">=</span>1 <span class="nt">--build-arg</span> <span class="nv">CUDA_VERSION</span><span class="o">=</span>12-6 <span class="nb">.</span>

</code></pre></div></div>

<p>Run the docker container. If you want to use CUDA, you have to install the <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">NVIDIA Container Tollkit</a> and add <code class="language-plaintext highlighter-rouge">--gpus all</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">-it</span> <span class="nt">--rm</span> <span class="nt">--gpus</span> all llama_ros

</code></pre></div></div>

<h2 id="usage">Usage</h2>

<h3 id="llama_cli">llama_cli</h3>

<p>Commands are included in llama_ros to speed up the test of GGUF-based LLMs within the ROS 2 ecosystem. This way, the following commands are integrating into the ROS 2 commands:</p>

<h4 id="launch">launch</h4>

<p>Using this command launch a LLM from a YAML file. The configuration of the YAML is used to launch the LLM in the same way as using a regular launch file. Here is an example of how to use it:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ros2 llama launch ~/ros2_ws/src/llama_ros/llama_bringup/models/StableLM-Zephyr.yaml

</code></pre></div></div>

<h4 id="prompt">prompt</h4>

<p>Using this command send a prompt to a launched LLM. The command uses a string, which is the prompt and has the following arguments:</p>

<ul>
  <li>(<code class="language-plaintext highlighter-rouge">-r</code>, <code class="language-plaintext highlighter-rouge">--reset</code>): Whether to reset the LLM before prompting</li>
  <li>(<code class="language-plaintext highlighter-rouge">-t</code>, <code class="language-plaintext highlighter-rouge">--temp</code>): The temperature value</li>
  <li>(<code class="language-plaintext highlighter-rouge">--image-url</code>): Image url to sent to a VLM</li>
</ul>

<p>Here is an example of how to use it:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ros2 llama prompt <span class="s2">"Do you know ROS 2?"</span> <span class="nt">-t</span> 0.0

</code></pre></div></div>

<h3 id="launch-files">Launch Files</h3>

<p>First of all, you need to create a launch file to use llama_ros or llava_ros. This launch file will contain the main parameters to download the model from HuggingFace and configure it. Take a look at the following examples and the <a href="https://github.com/mgonzs13/llama_ros/tree/main/llama_bringup/launch">predefined launch files</a>.</p>

<h4 id="llama_ros-python-launch">llama_ros (Python Launch)</h4>

<details>
<summary>Click to expand</summary>


```python
from launch import LaunchDescription
from llama_bringup.utils import create_llama_launch


def generate_launch_description():

    return LaunchDescription([
        create_llama_launch(
            n_ctx=2048, # context of the LLM in tokens
            n_batch=8, # batch size in tokens
            n_gpu_layers=0, # layers to load in GPU
            n_threads=1, # threads
            n_predict=2048, # max tokens, -1 == inf

            model_repo="TheBloke/Marcoroni-7B-v3-GGUF", # Hugging Face repo
            model_filename="marcoroni-7b-v3.Q4_K_M.gguf", # model file in repo

            system_prompt_type="Alpaca" # system prompt type
        )
    ])

```


```bash
ros2 launch llama_bringup marcoroni.launch.py

```

</details>

<h4 id="llama_ros-yaml-config">llama_ros (YAML Config)</h4>

<details>
<summary>Click to expand</summary>


```yaml
n_ctx: 2048 # context of the LLM in tokens
n_batch: 8 # batch size in tokens
n_gpu_layers: 0 # layers to load in GPU
n_threads: 1 # threads
n_predict: 2048 # max tokens, -1 == inf

model_repo: "cstr/Spaetzle-v60-7b-GGUF" # Hugging Face repo
model_filename: "Spaetzle-v60-7b-q4-k-m.gguf" # model file in repo

system_prompt_type: "Alpaca" # system prompt type

```


```python
import os
from launch import LaunchDescription
from llama_bringup.utils import create_llama_launch_from_yaml
from ament_index_python.packages import get_package_share_directory


def generate_launch_description():
    return LaunchDescription([
        create_llama_launch_from_yaml(os.path.join(
            get_package_share_directory("llama_bringup"), "models", "Spaetzle.yaml"))
    ])

```


```bash
ros2 launch llama_bringup spaetzle.launch.py

```

</details>

<h4 id="llama_ros-yaml-config--model-shards">llama_ros (YAML Config + model shards)</h4>

<details>
<summary>Click to expand</summary>


```yaml
n_ctx: 2048 # context of the LLM in tokens
n_batch: 8 # batch size in tokens
n_gpu_layers: 0 # layers to load in GPU
n_threads: 1 # threads
n_predict: 2048 # max tokens, -1 == inf

model_repo: "Qwen/Qwen2.5-Coder-7B-Instruct-GGUF" # Hugging Face repo
model_filename: "qwen2.5-coder-7b-instruct-q4_k_m-00001-of-00002.gguf" # model shard file in repo

system_prompt_type: "ChatML" # system prompt type

```


```bash
ros2 llama launch Qwen2.yaml

```

</details>

<h4 id="llava_ros-python-launch">llava_ros (Python Launch)</h4>

<details>
<summary>Click to expand</summary>


```python
from launch import LaunchDescription
from llama_bringup.utils import create_llama_launch

def generate_launch_description():

    return LaunchDescription([
        create_llama_launch(
            use_llava=True, # enable llava

            n_ctx=8192, # context of the LLM in tokens, use a huge context size to load images
            n_batch=512, # batch size in tokens
            n_gpu_layers=33, # layers to load in GPU
            n_threads=1, # threads
            n_predict=8192, # max tokens, -1 == inf

            model_repo="cjpais/llava-1.6-mistral-7b-gguf", # Hugging Face repo
            model_filename="llava-v1.6-mistral-7b.Q4_K_M.gguf", # model file in repo

            mmproj_repo="cjpais/llava-1.6-mistral-7b-gguf", # Hugging Face repo
            mmproj_filename="mmproj-model-f16.gguf", # mmproj file in repo

            system_prompt_type="Mistral" # system prompt type
        )
    ])

```


```bash
ros2 launch llama_bringup llava.launch.py

```

</details>

<h4 id="llava_ros-yaml-config">llava_ros (YAML Config)</h4>

<details>
<summary>Click to expand</summary>


```yaml
use_llava: True # enable llava

n_ctx: 8192 # context of the LLM in tokens use a huge context size to load images
n_batch: 512 # batch size in tokens
n_gpu_layers: 33 # layers to load in GPU
n_threads: 1 # threads
n_predict: 8192 # max tokens -1 : :  inf

model_repo: "cjpais/llava-1.6-mistral-7b-gguf" # Hugging Face repo
model_filename: "llava-v1.6-mistral-7b.Q4_K_M.gguf" # model file in repo

mmproj_repo: "cjpais/llava-1.6-mistral-7b-gguf" # Hugging Face repo
mmproj_filename: "mmproj-model-f16.gguf" # mmproj file in repo

system_prompt_type: "mistral" # system prompt type

```


```python
def generate_launch_description():
    return LaunchDescription([
        create_llama_launch_from_yaml(os.path.join(
            get_package_share_directory("llama_bringup"),
            "models", "llava-1.6-mistral-7b-gguf.yaml"))
    ])

```


```bash
ros2 launch llama_bringup llava.launch.py

```

</details>

<h3 id="lora-adapters">LoRA Adapters</h3>

<p>You can use LoRA adapters when launching LLMs. Using llama.cpp features, you can load multiple adapters choosing the scale to apply for each adapter. Here you have an example of using LoRA adapters with Phi-3. You can lis the
LoRAs using the <code class="language-plaintext highlighter-rouge">/llama/list_loras</code> service and modify their scales values by using the <code class="language-plaintext highlighter-rouge">/llama/update_loras</code> service. A scale value of 0.0 means not using that LoRA.</p>

<details>
<summary>Click to expand</summary>


```yaml
n_ctx: 2048
n_batch: 8
n_gpu_layers: 0
n_threads: 1
n_predict: 2048

model_repo: "bartowski/Phi-3.5-mini-instruct-GGUF"
model_filename: "Phi-3.5-mini-instruct-Q4_K_M.gguf"

lora_adapters:
  - repo: "zhhan/adapter-Phi-3-mini-4k-instruct_code_writing"
    filename: "Phi-3-mini-4k-instruct-adaptor-f16-code_writer.gguf"
    scale: 0.5
  - repo: "zhhan/adapter-Phi-3-mini-4k-instruct_summarization"
    filename: "Phi-3-mini-4k-instruct-adaptor-f16-summarization.gguf"
    scale: 0.5

system_prompt_type: "Phi-3"

```

</details>

<h3 id="ros-2-clients">ROS 2 Clients</h3>

<p>Both llama_ros and llava_ros provide ROS 2 interfaces to access the main functionalities of the models. Here you have some examples of how to use them inside ROS 2 nodes. Moreover, take a look to the <a href="https://github.com/mgonzs13/llama_ros/tree/main/llama_demos/llama_demos/llama_demo_node.py">llama_demo_node.py</a> and <a href="https://github.com/mgonzs13/llama_ros/tree/main/llama_demos/llama_demos/llava_demo_node.py">llava_demo_node.py</a> demos.</p>

<h4 id="tokenize">Tokenize</h4>

<details>
<summary>Click to expand</summary>


```python
from rclpy.node import Node
from llama_msgs.srv import Tokenize


class ExampleNode(Node):
    def __init__(self) -&gt; None:
        super().__init__("example_node")

        # create the client
        self.srv_client = self.create_client(Tokenize, "/llama/tokenize")

        # create the request
        req = Tokenize.Request()
        req.text = "Example text"

        # call the tokenize service
        self.srv_client.wait_for_service()
        tokens = self.srv_client.call(req).tokens

```

</details>

<h4 id="detokenize">Detokenize</h4>

<details>
<summary>Click to expand</summary>


```python
from rclpy.node import Node
from llama_msgs.srv import Detokenize


class ExampleNode(Node):
    def __init__(self) -&gt; None:
        super().__init__("example_node")

        # create the client
        self.srv_client = self.create_client(Detokenize, "/llama/detokenize")

        # create the request
        req = Detokenize.Request()
        req.tokens = [123, 123]

        # call the tokenize service
        self.srv_client.wait_for_service()
        text = self.srv_client.call(req).text

```

</details>

<h4 id="embeddings">Embeddings</h4>

<details>
<summary>Click to expand</summary>

_Remember to launch llama_ros with embedding set to true to be able of generating embeddings with your LLM._


```python
from rclpy.node import Node
from llama_msgs.srv import Embeddings


class ExampleNode(Node):
    def __init__(self) -&gt; None:
        super().__init__("example_node")

        # create the client
        self.srv_client = self.create_client(Embeddings, "/llama/generate_embeddings")

        # create the request
        req = Embeddings.Request()
        req.prompt = "Example text"
        req.normalize = True

        # call the embedding service
        self.srv_client.wait_for_service()
        embeddings = self.srv_client.call(req).embeddings

```

</details>

<h4 id="generate-response">Generate Response</h4>

<details>
<summary>Click to expand</summary>


```python
import rclpy
from rclpy.node import Node
from rclpy.action import ActionClient
from llama_msgs.action import GenerateResponse


class ExampleNode(Node):
    def __init__(self) -&gt; None:
        super().__init__("example_node")

        # create the client
        self.action_client = ActionClient(
            self, GenerateResponse, "/llama/generate_response")

        # create the goal and set the sampling config
        goal = GenerateResponse.Goal()
        goal.prompt = self.prompt
        goal.sampling_config.temp = 0.2

        # wait for the server and send the goal
        self.action_client.wait_for_server()
        send_goal_future = self.action_client.send_goal_async(
            goal)

        # wait for the server
        rclpy.spin_until_future_complete(self, send_goal_future)
        get_result_future = send_goal_future.result().get_result_async()

        # wait again and take the result
        rclpy.spin_until_future_complete(self, get_result_future)
        result: GenerateResponse.Result = get_result_future.result().result

```

</details>

<h4 id="generate-response-llava">Generate Response (llava)</h4>

<details>
<summary>Click to expand</summary>


```python
import cv2
from cv_bridge import CvBridge

import rclpy
from rclpy.node import Node
from rclpy.action import ActionClient
from llama_msgs.action import GenerateResponse


class ExampleNode(Node):
    def __init__(self) -&gt; None:
        super().__init__("example_node")

        # create a cv bridge for the image
        self.cv_bridge = CvBridge()

        # create the client
        self.action_client = ActionClient(
            self, GenerateResponse, "/llama/generate_response")

        # create the goal and set the sampling config
        goal = GenerateResponse.Goal()
        goal.prompt = self.prompt
        goal.sampling_config.temp = 0.2

        # add your image to the goal
        image = cv2.imread("/path/to/your/image", cv2.IMREAD_COLOR)
        goal.image = self.cv_bridge.cv2_to_imgmsg(image)

        # wait for the server and send the goal
        self.action_client.wait_for_server()
        send_goal_future = self.action_client.send_goal_async(
            goal)

        # wait for the server
        rclpy.spin_until_future_complete(self, send_goal_future)
        get_result_future = send_goal_future.result().get_result_async()

        # wait again and take the result
        rclpy.spin_until_future_complete(self, get_result_future)
        result: GenerateResponse.Result = get_result_future.result().result

```

</details>

<h3 id="langchain">LangChain</h3>

<p>There is a <a href="https://github.com/mgonzs13/llama_ros/tree/main/llama_ros/llama_ros/langchain/">llama_ros integration for LangChain</a>. Thus, prompt engineering techniques could be applied. Here you have an example to use it.</p>

<h4 id="llama_ros-chain">llama_ros (Chain)</h4>

<details>
<summary>Click to expand</summary>


```python
import rclpy
from llama_ros.langchain import LlamaROS
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser


rclpy.init()

# create the llama_ros llm for langchain
llm = LlamaROS()

# create a prompt template
prompt_template = "tell me a joke about {topic}"
prompt = PromptTemplate(
    input_variables=["topic"],
    template=prompt_template
)

# create a chain with the llm and the prompt template
chain = prompt | llm | StrOutputParser()

# run the chain
text = chain.invoke({"topic": "bears"})
print(text)

rclpy.shutdown()

```

</details>

<h4 id="llama_ros-stream">llama_ros (Stream)</h4>

<details>
<summary>Click to expand</summary>


```python
import rclpy
from llama_ros.langchain import LlamaROS
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser


rclpy.init()

# create the llama_ros llm for langchain
llm = LlamaROS()

# create a prompt template
prompt_template = "tell me a joke about {topic}"
prompt = PromptTemplate(
    input_variables=["topic"],
    template=prompt_template
)

# create a chain with the llm and the prompt template
chain = prompt | llm | StrOutputParser()

# run the chain
for c in chain.stream({"topic": "bears"}):
    print(c, flush=True, end="")

rclpy.shutdown()

```

</details>

<h4 id="llava_ros">llava_ros</h4>

<details>
<summary>Click to expand</summary>


```python
import rclpy
from llama_ros.langchain import LlamaROS

rclpy.init()

# create the llama_ros llm for langchain
llm = LlamaROS()

# bind the url_image
image_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
llm = llm.bind(image_url=image_url).stream("Describe the image")

# run the llm
for c in llm:
    print(c, flush=True, end="")

rclpy.shutdown()

```

</details>

<h4 id="llama_ros_embeddings-rag">llama_ros_embeddings (RAG)</h4>

<details>
<summary>Click to expand</summary>


```python
import rclpy
from langchain_chroma import Chroma
from llama_ros.langchain import LlamaROSEmbeddings


rclpy.init()

# create the llama_ros embeddings for langchain
embeddings = LlamaROSEmbeddings()

# create a vector database and assign it
db = Chroma(embedding_function=embeddings)

# create the retriever
retriever = db.as_retriever(search_kwargs={"k": 5})

# add your texts
db.add_texts(texts=["your_texts"])

# retrieve documents
documents = retriever.invoke("your_query")
print(documents)

rclpy.shutdown()

```

</details>

<h4 id="llama_ros-renranker">llama_ros (Renranker)</h4>

<details>
<summary>Click to expand</summary>


```python
import rclpy
from llama_ros.langchain import LlamaROSReranker
from llama_ros.langchain import LlamaROSEmbeddings

from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.retrievers import ContextualCompressionRetriever


rclpy.init()

# load the documents
documents = TextLoader("../state_of_the_union.txt",).load()
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500, chunk_overlap=100)
texts = text_splitter.split_documents(documents)

# create the llama_ros embeddings
embeddings = LlamaROSEmbeddings()

# create the VD and the retriever
retriever = FAISS.from_documents(
    texts, embeddings).as_retriever(search_kwargs={"k": 20})

# create the compressor using the llama_ros reranker
compressor = LlamaROSReranker()
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor, base_retriever=retriever
)

# retrieve the documents
compressed_docs = compression_retriever.invoke(
    "What did the president say about Ketanji Jackson Brown"
)

for doc in compressed_docs:
    print("-" * 50)
    print(doc.page_content)
    print("\n")

rclpy.shutdown()

```

</details>

<h4 id="llama_ros-llm--rag--reranker">llama_ros (LLM + RAG + Reranker)</h4>

<details>
<summary>Click to expand</summary>


```python
import bs4
import rclpy

from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.messages import SystemMessage
from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.retrievers import ContextualCompressionRetriever

from llama_ros.langchain import ChatLlamaROS, LlamaROSEmbeddings, LlamaROSReranker


rclpy.init()

# load, chunk and index the contents of the blog
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(class_=("post-content", "post-title", "post-header"))
    ),
)
docs = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)
vectorstore = Chroma.from_documents(documents=splits, embedding=LlamaROSEmbeddings())

# retrieve and generate using the relevant snippets of the blog
retriever = vectorstore.as_retriever(search_kwargs={"k": 20})

# create prompt
prompt = ChatPromptTemplate.from_messages(
    [
        SystemMessage("You are an AI assistant that answer questions briefly."),
        HumanMessagePromptTemplate.from_template(
            "Taking into account the followin information:{context}\n\n{question}"
        ),
    ]
)

# create rerank compression retriever
compressor = LlamaROSReranker(top_n=3)
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor, base_retriever=retriever
)


def format_docs(docs):
    formated_docs = ""

    for d in docs:
        formated_docs += f"\n\n\t- {d.page_content}"

    return formated_docs


# create and use the chain
rag_chain = (
    {"context": compression_retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | ChatLlamaROS(temp=0.0)
    | StrOutputParser()
)

for c in rag_chain.stream("What is Task Decomposition?"):
    print(c, flush=True, end="")

rclpy.shutdown()

```

</details>

<h4 id="chat_llama_ros-chat--vlm">chat_llama_ros (Chat + VLM)</h4>

<details>
<summary>Click to expand</summary>


```python
import rclpy
from llama_ros.langchain import ChatLlamaROS
from langchain_core.messages import SystemMessage
from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser


rclpy.init()

# create chat
chat = ChatLlamaROS(
    temp=0.2,
    penalty_last_n=8
)

# create prompt template with messages
prompt = ChatPromptTemplate.from_messages([
    SystemMessage("You are a IA that just answer with a single word."),
    HumanMessagePromptTemplate.from_template(template=[
        {"type": "text", "text": "<image>Who is the character in the middle of the image?"},
        {"type": "image_url", "image_url": "{image_url}"}
    ])
])

# create the chain
chain = prompt | chat | StrOutputParser()

# stream and print the LLM output
for text in chain.stream({"image_url": "https://pics.filmaffinity.com/Dragon_Ball_Bola_de_Dragaon_Serie_de_TV-973171538-large.jpg"}):
    print(text, end="", flush=True)

print("", end="\n", flush=True)

rclpy.shutdown()

```

&lt;/details&gt;

&lt;/details&gt;

#### chat_llama_ros (Structured output)

<details>
<summary>Click to expand</summary>


```python
import rclpy

from langchain_core.messages import HumanMessage
from llama_ros.langchain import ChatLlamaROS
from pydantic import BaseModel, Field

rclpy.init()

class Joke(BaseModel):
    """Joke to tell user."""

    setup: str = Field(description="The setup of the joke")
    punchline: str = Field(description="The punchline to the joke")
    rating: Optional[int] = Field(
        default=None, description="How funny the joke is, from 1 to 10"
    )

chat = ChatLlamaROS(temp=0.6, penalty_last_n=8)

structured_chat = chat.with_structured_output(
    Joke, method="function_calling"
)

prompt = ChatPromptTemplate.from_messages(
    [
        HumanMessagePromptTemplate.from_template(
            template=[
                {"type": "text", "text": "{prompt}"},
            ]
        ),
    ]
)

chain = prompt | structured_chat

res = chain.invoke({"prompt": "Tell me a joke about cats"})

print(f"Response: {response.content.strip()}")

rclpy.shutdown()

```

</details>

#### chat_llama_ros (Tools)

<details>
<summary>Click to expand</summary>

The current implementation of Tools allows executing tools without requiring a model trained for that task.


```python
from random import randint

import rclpy

from langchain.tools import tool
from langchain_core.messages import HumanMessage
from llama_ros.langchain import ChatLlamaROS

rclpy.init()

@tool
def get_inhabitants(city: str) -&gt; int:
    """Get the current temperature of a city"""
    return randint(4_000_000, 8_000_000)


@tool
def get_curr_temperature(city: str) -&gt; int:
    """Get the current temperature of a city"""
    return randint(20, 30)

chat = ChatLlamaROS(temp=0.6, penalty_last_n=8)

messages = [
    HumanMessage(
        "What is the current temperature in Madrid? And its inhabitants?"
    )
]

llm_tools = chat.bind_tools(
    [get_inhabitants, get_curr_temperature], tool_choice='any'
)

all_tools_res = llm_tools.invoke(messages)
messages.append(all_tools_res)

for tool in all_tools_res.tool_calls:
    selected_tool = {
        "get_inhabitants": get_inhabitants, "get_curr_temperature": get_curr_temperature
    }[tool['name']]

    tool_msg = selected_tool.invoke(tool)

    formatted_output = f"{tool['name']}({''.join(tool['args'].values())}) = {tool_msg.content}"

    tool_msg.additional_kwargs = {'args': tool['args']}
    messages.append(tool_msg)

res = llm_tools.invoke(messages)

print(f"Response: {res.content}")

rclpy.shutdown()

```

</details>

#### chat_llama_ros (Reasoning)

<details>
<summary>Click to expand</summary>

A reasoning model is required, such as Deepseek R1


```python
import time
from random import randint

import rclpy

from langchain_core.messages import HumanMessage
from llama_ros.langchain import ChatLlamaROS

rclpy.init()

chat = ChatLlamaROS(temp=0.6, penalty_last_n=8)

messages = [
    HumanMessage(
        "Here we have a book, a laptop, 9 eggs and a nail. Please tell me how to stack them onto each other in a stable manner."
    )
]

res = chat.invoke(messages)

print(f"Response: {res.content.strip()}")
print(f"Reasoning: {res.additional_kwargs["reasoning_content"]}")

rclpy.shutdown()

```

</details>

#### chat_llama_ros (langgraph)

<details>
<summary>Click to expand</summary>


```python
import time
from random import randint

import rclpy

from langchain.tools import tool
from langchain_core.messages import HumanMessage
from langgraph.prebuilt import create_react_agent
from llama_ros.langchain import ChatLlamaROS

rclpy.init()

@tool
def get_inhabitants(city: str) -&gt; int:
    """Get the current temperature of a city"""
    return randint(4_000_000, 8_000_000)


@tool
def get_curr_temperature(city: str) -&gt; int:
    """Get the current temperature of a city"""
    return randint(20, 30)

chat = ChatLlamaROS(temp=0.0)

agent_executor = create_react_agent(
    self.chat, [get_inhabitants, get_curr_temperature]
)

response = self.agent_executor.invoke(
    {
        "messages": [
            HumanMessage(
                content="What is the current temperature in Madrid? And its inhabitants?"
            )
        ]
    }
)

print(f"Response: {response['messages'][-1].content}")

rclpy.shutdown()

```

</details>

## Demos

### LLM Demo


```bash
ros2 launch llama_bringup spaetzle.launch.py

```


```bash
ros2 run llama_demos llama_demo_node

```

<!-- https://user-images.githubusercontent.com/25979134/229344687-9dda3446-9f1f-40ab-9723-9929597a042c.mp4 -->

https://github.com/mgonzs13/llama_ros/assets/25979134/9311761b-d900-4e58-b9f8-11c8efefdac4

### Embeddings Generation Demo


```bash
ros2 llama launch ~/ros2_ws/src/llama_ros/llama_bringup/models/bge-base-en-v1.5.yaml

```


```bash
ros2 run llama_demos llama_embeddings_demo_node

```

https://github.com/user-attachments/assets/7d722017-27dc-417c-ace7-bf6b747e4ced

### Reranking Demo


```bash
ros2 llama launch ~/ros2_ws/src/llama_ros/llama_bringup/models/jina-reranker.yaml

```


```bash
ros2 run llama_demos llama_rerank_demo_node

```

https://github.com/user-attachments/assets/4b4adb4d-7c70-43ea-a2c1-9be57d211484

### VLM Demo


```bash
ros2 launch llama_bringup minicpm-2.6.launch.py

```


```bash
ros2 run llama_demos llava_demo_node --ros-args -p prompt:="your prompt" -p image_url:="url of the image" -p use_image:="whether to send the image"

```

https://github.com/mgonzs13/llama_ros/assets/25979134/4a9ef92f-9099-41b4-8350-765336e3503c

### Chat Template Demo


```bash
ros2 llama launch MiniCPM-2.6.yaml

```

<details>
<summary>Click to expand MiniCPM-2.6.yaml</summary>


```yaml
use_llava: True

n_ctx: 8192
n_batch: 512
n_gpu_layers: 20
n_threads: -1
n_predict: 8192

image_prefix: "<image>"
image_suffix: "</image>"

model_repo: "openbmb/MiniCPM-V-2_6-gguf"
model_filename: "ggml-model-Q4_K_M.gguf"

mmproj_repo: "openbmb/MiniCPM-V-2_6-gguf"
mmproj_filename: "mmproj-model-f16.gguf"

```

</details>


```bash
ros2 run llama_demos chatllama_demo_node

```

[ChatLlamaROS demo](https://github-production-user-asset-6210df.s3.amazonaws.com/55236157/363094669-c6de124a-4e91-4479-99b6-685fecb0ac20.webm?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240830%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20240830T081232Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=f937758f4bcbaec7683e46ddb057fb642dc86a33cc8c736fca3b5ce2bf06ddac&amp;X-Amz-SignedHeaders=host&amp;actor_id=55236157&amp;key_id=0&amp;repo_id=622137360)

### Chat Structed Output Demo


```bash
ros2 llama launch Qwen2.yaml

```


```bash
ros2 run llama_demos chatllama_structured_demo_node

```

[Structured Output ChatLlama](https://github.com/user-attachments/assets/e0bf4031-50c0-4790-94a0-1f6aed5734ec)

### Chat Tools Demo


```bash
ros2 llama launch Qwen2.yaml

```


```bash
ros2 run llama_demos chatllama_tools_demo_node

```

[Tools ChatLlama](https://github.com/user-attachments/assets/b912ee29-1466-4d6a-888b-9a2d9c16ae1d)

### Chat Reasoning Demo (DeepSeek-R1)


```bash
ros2 llama launch DeepSeek-R1.yaml

```


```bash
ros2 run llama_demos chatllama_reasoning_demo_node

```

[DeepSeekR1 ChatLlama](https://github.com/user-attachments/assets/3f268614-eabc-4499-b50f-a76d76908d9d)

### Langgraph Demo


```bash
ros2 llama launch Qwen2.yaml

```

<details>
<summary>Click to expand Qwen2.yaml</summary>


```yaml
_ctx: 4096
n_batch: 256
n_gpu_layers: 29
n_threads: -1
n_predict: -1

model_repo: "Qwen/Qwen2.5-Coder-7B-Instruct-GGUF"
model_filename: "qwen2.5-coder-7b-instruct-q4_k_m-00001-of-00002.gguf"

```

</details>


```bash
ros2 run llama_demos chatllama_langgraph_demo_node

```

[Langgraph ChatLlama](https://github.com/user-attachments/assets/a0991cb4-f7f4-43d5-b629-3b1819aead0d)

### RAG Demo (LLM + chat template + RAG + Reranking + Stream)


```bash
ros2 llama launch ~/ros2_ws/src/llama_ros/llama_bringup/models/bge-base-en-v1.5.yaml

```


```bash
ros2 llama launch ~/ros2_ws/src/llama_ros/llama_bringup/models/jina-reranker.yaml

```


```bash
ros2 llama launch Qwen2.yaml

```

<details>
<summary>Click to expand Qwen2.yaml</summary>


```yaml
_ctx: 4096
n_batch: 256
n_gpu_layers: 29
n_threads: -1
n_predict: -1

model_repo: "Qwen/Qwen2.5-Coder-3B-Instruct-GGUF"
model_filename: "qwen2.5-coder-3b-instruct-q4_k_m.gguf"

```

</details>


```bash
ros2 run llama_demos llama_rag_demo_node

```

https://github.com/user-attachments/assets/b4e3957d-1f92-427b-a1a8-cfc76737c0d6
</image></details>
</div>
            
          </div>
        </div>

        <div class="panel panel-default">
          <div class="panel-heading"><h3 class="panel-title">CONTRIBUTING</h3></div>
          <div class="panel-body">
            
              <em>No CONTRIBUTING.md found.</em>
            
          </div>
        </div>

        
        
      
    </div>
  </div>

  <div class="distro distro-noetic">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/llama_ros">llama_ros</a> <small>repository</small></h3>
        <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-mgonzs13-llama_ros
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-mgonzs13-llama_ros" role="menuitem" tabindex="-1" href="/r/llama_ros/github-mgonzs13-llama_ros" data="github-mgonzs13-llama_ros">
                    <span class="glyphicon glyphicon-star"></span>
                    github-mgonzs13-llama_ros
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>noetic</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-galactic">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/llama_ros">llama_ros</a> <small>repository</small></h3>
        <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-mgonzs13-llama_ros
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-mgonzs13-llama_ros" role="menuitem" tabindex="-1" href="/r/llama_ros/github-mgonzs13-llama_ros" data="github-mgonzs13-llama_ros">
                    <span class="glyphicon glyphicon-star"></span>
                    github-mgonzs13-llama_ros
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>galactic</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-iron">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/llama_ros">llama_ros</a> <small>repository</small></h3>
        <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-mgonzs13-llama_ros
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-mgonzs13-llama_ros" role="menuitem" tabindex="-1" href="/r/llama_ros/github-mgonzs13-llama_ros" data="github-mgonzs13-llama_ros">
                    <span class="glyphicon glyphicon-star"></span>
                    github-mgonzs13-llama_ros
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>iron</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>

  <div class="distro distro-melodic">
    <div class="container-fluid">
      <div class="well well-sm">
  <div>
    
  </div>
  
  <table class="table">
    <tr>
      <td width="100px" class="text-center">
        <img style="width: 80px;" src="/assets/repo.png">
      </td>
      <td>
        <h3><a style="text-decoration:none;" href="/r/llama_ros">llama_ros</a> <small>repository</small></h3>
        <span class="label label-default">cpp</span> <span class="label label-default">embeddings</span> <span class="label label-default">llama</span> <span class="label label-default">gpt</span> <span class="label label-default">ros2</span> <span class="label label-default">vlm</span> <span class="label label-default">reranking</span> <span class="label label-default">llm</span> <span class="label label-default">langchain</span> <span class="label label-default">llava</span> <span class="label label-default">llamacpp</span> <span class="label label-default">ggml</span> <span class="label label-default">gguf</span> <span class="label label-default">rerank</span> <span class="label label-default">llavacpp</span> 
        

      </td>
    </tr>
  </table>
  <div class="top-buffer">
    
    
<table class="table table-condensed instance-switch">
  <tr>
    <td>
      <div id="repo-switch" class="btn-group btn-group-justified" role="group">
        <div class="btn-group" style="width: 90%" role="group">
          <div class="dropdown">
            <!-- TODO: add disabled when only 1 version is known? -->
            <button class="btn btn-xs btn-default dropdown-toggle" type="button" id="dropdownMenu1" data-toggle="dropdown" title="Select Instance">
              <span class="pull-left" style="width: 100%; text-align: left">
                <span class="pull-right"><span class="caret"></span></span> 
              <span class="glyphicon glyphicon-star"></span>
                  github-mgonzs13-llama_ros
              </span>
            </button>
            <ul class="dropdown-menu" role="menu">
              
                <li role="presentation">
                  <a id="github-mgonzs13-llama_ros" role="menuitem" tabindex="-1" href="/r/llama_ros/github-mgonzs13-llama_ros" data="github-mgonzs13-llama_ros">
                    <span class="glyphicon glyphicon-star"></span>
                    github-mgonzs13-llama_ros
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </td>
  </tr>
</table>

  </div>
  <div class="top-buffer">
  </div>
</div>

      
        <div class="alert alert-warning" role="alert">No version for distro <strong>melodic</strong>. Known supported distros are highlighted in the buttons above.</div>
      
    </div>
  </div>


<script src=/js/contribution_suggestions.js></script>
<script type="text/javascript">
  $(function() {
    setupContributeListTabLinks();
  });
  $(document).ready(function() {
    setupDistroSwitch("humble");
    setupContributeLists("https://github.com/mgonzs13/llama_ros.git");
  });
</script>

      </div>
    </div>

    <footer class="site-footer">
  <div class="wrapper">
    <div class="container-fluid">
      <div style="float:left;">
        
          <a href="https://github.com/rkent/rosindex" title="Find rosindex in Github">
          <span class="icon  icon--github">
            <svg viewBox="0 0 16 16">
              <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
            </svg>
          </span>

          <span class="username">rkent/rosindex</span>
        </a>
        <em class="hidden-xs">| generated on 2025-05-05</em>
      
      </div>
      <div style="float:right;">
        <p class="text"><span class="hidden-xs">a community-maintained index of robotics software
 | </span><a href="/privacy.txt">privacy</a></p>
      </div>
    </div>
  </div>

</footer>


  </body>

</html>
